---
title: åˆè¯•Rust Burnè®­ç»ƒæ¨¡å‹
description: è®°å½•ä¸€ä¸‹é¦–æ¬¡å°è¯•ç”¨Rustä¸Burnæ¡†æ¶å®Œæˆä¸€ä¸ªç®€å•æ—¶é—´åºåˆ—é¢„æµ‹Transformerçš„è®­ç»ƒ
slug: burn-demo
date: 2024-05-05 00:00:00+0000
image: cover.jpg
categories:
    - dev
    - ai
tags:
    - dev
    - ai
---

> æœ€è¿‘æŠ˜è…¾åŸºäºPythonçš„äººå·¥æ™ºèƒ½ç›¸å…³çš„é¡¹ç›®æ¯”è¾ƒå¤šï¼ŒPythonå†™èµ·æ¥æ˜¯å¿«ï¼Œä½†æ˜¯è¿™ä¸ªé¡¹ç›®çš„å¯ç§»æ¤æ€§å¯è°“æ˜¯èŠèƒœäºæ— ï¼Œå°¤å…¶åŒ…ç®¡ç†å™¨pipéš¾ç”¨çš„ç¦»è°±ï¼Œæ‰€ä»¥å½“éœ€è¦è‡ªå·±å†™æ¨¡å‹çš„æ—¶å€™æœæ–­æ”¾å¼ƒPythonï¼Œ
> æ¢äº†Rustæ¥å†™ï¼ŒRuståŸºç¡€çš„æœºå™¨å­¦ä¹ åº“æ¯”è¾ƒå®Œå–„çš„æœ‰HuggingFaceå¼€æºçš„Candleï¼Œä½†æ˜¯Candleæ›´åå‘åº•å±‚ï¼Œå¹¶ä¸èƒ½åƒPytorché‚£æ ·æä¾›ä¸€äº›ç°æœ‰çš„å±‚ï¼Œæ¯”å¦‚Transformerã€LSTMç­‰ï¼Œ
> åŒæ—¶å†è€ƒè™‘åˆ°æ¨ç†ã€è®­ç»ƒçš„åç«¯å¯ç§»æ¤æ€§ï¼Œåˆ‡æ¢åˆ°äº†ä¸€ä¸ªæ¯”è¾ƒæ–°çš„Burnæ¡†æ¶ä¸Šã€‚  
> Burnæœ¬èº«ä¸æä¾›ç®—å­æ ¸å¿ƒï¼Œå®ƒä¾èµ–äºCandleæˆ–è€…WGPUæ¥æä¾›åç«¯AutoGradï¼Œå› æ­¤ä½œä¸ºä¸€ä¸ªé«˜åº¦æŠ½è±¡çš„APIèƒ½å¤Ÿä¿æŒè‰¯å¥½çš„å¯ç§»æ¤æ€§ï¼ŒåŒæ—¶Burnæä¾›äº†ä¸€äº›å†…ç½®çš„å±‚ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºLSTMã€Transformer Encoderç­‰ï¼Œ
> æœ¬æ–‡åªæ˜¯ä¸€äº›ç®€å•çš„è¸©å‘ï¼Œæ€»ä½“æ¥è¯´è¿˜æ˜¯å¾ˆçœ‹å¥½åŸºäºRustçš„äººå·¥æ™ºèƒ½è®­ç»ƒä¸æ¨ç†çš„æœªæ¥ã€‚

## æ•°æ®åŠ è½½
é¦–å…ˆéœ€è¦å†™ä¸€ä¸ªstructæ¥ä½œä¸ºè¾“å…¥çš„åŸå­æ•°æ®(å¤§æ¦‚è¿™ä¸ªæ„æ€)ï¼ŒåŒæ—¶æˆ‘ä»¬éœ€è¦è‡ªå®šä¹‰ä¸€ä¸ªååºåˆ—åŒ–å‡½æ•°æ¥æŠŠå­—ç¬¦ä¸²ç±»å‹çš„æ—¶é—´å˜ä¸ºUNIXæ—¶é—´æˆ³æ¥æ–¹ä¾¿transformerç†è§£
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SatelliteStatus {
    pub name: String,
    #[serde(deserialize_with = "datetime_to_timestamp")]
    pub time: i64,
    pub range: f64,
    #[serde(rename = "SNR")]
    pub snr: f64,
    #[serde(rename = "t")]
    pub latency: f64,
    pub channel_capacity: f64,
}

fn datetime_to_timestamp<'de, D>(deserializer: D) -> Result<i64, D::Error>
where
    D: Deserializer<'de>,
{
    let s = String::deserialize(deserializer)?;
    let dt = NaiveDateTime::parse_from_str(&s, "%d %b %Y %H:%M:%S%.3f")
        .expect("Failed to turn datetime to timestamp");
    Ok(dt.and_utc().timestamp())
}

pub fn load_satellite_status(data_path: String) -> Vec<SatelliteStatus> {
    let data = std::fs::File::open(data_path).expect("Failed to open satellite status file");
    serde_json::from_reader(data).expect("Failed to load satellite status")
}
```

ç”±äºä»»åŠ¡æ˜¯æ—¶é—´åºåˆ—é¢„æµ‹ï¼Œéœ€è¦è¾“å…¥10ä¸ªæ—¶åˆ»æ•°æ®ï¼Œè¾“å‡ºä¸‹ä¸€ä¸ªæ—¶åˆ»çš„æ•°æ®ï¼Œå› æ­¤æä¸€ä¸ªtype
```rust
pub type SatelliteStatusTimeSeriesData = [SatelliteStatus; 11];
```

ä¹‹åéœ€è¦å®ç°Burnçš„æ•°æ®é›†æ¥å£ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ª
```rust
pub struct SatelliteStatusTimeSeriesDataset {
    pub dataset: InMemDataset<SatelliteStatusTimeSeriesData>,
}
```
åœ¨è¿™ä¸ªä»»åŠ¡é‡Œç”±äºæ•°æ®é‡è¾ƒå°‘æ²¡æœ‰è¿›è¡ŒäºŒè¿›åˆ¶æ•°æ®ç¼“å­˜çš„å¤„ç†ï¼Œè™½ç„¶åŠ è½½ç•¥æ…¢ä½†æ˜¯é—®é¢˜ä¸å¤§ï¼Œå¦‚æœæ•°æ®é‡æ›´å¤§çš„è¯å…¶å®æœ€å¥½æ˜¯ä»CSVæˆ–JSONç­‰è¯»å–å¹¶å¤„ç†å®Œæ•°æ®åå†è¿›è¡ŒäºŒè¿›åˆ¶ç¼“å­˜  
ç„¶åéœ€è¦å®ç°æ•°æ®é›†çš„åŠ è½½å‡½æ•°ï¼ŒæŒ‰ç…§æ—¶é—´åºåˆ—æä¸€ä¸ªæ»‘åŠ¨çª—å£ï¼Œæ¯æ¬¡å–11ä¸ªæ—¶åˆ»çš„æ•°æ®ï¼Œå‰10ä¸ªä½œä¸ºè¾“å…¥ï¼Œæœ€åä¸€ä¸ªä½œä¸ºè¾“å‡º
```rust
impl SatelliteStatusTimeSeriesDataset {
    pub fn new() -> anyhow::Result<Self> {
        info!("Loading satellite status");
        const DATA_PATH: &str = "./data";
        let mut statuses: Vec<SatelliteStatus> = Vec::new();
        let entries = std::fs::read_dir(DATA_PATH).expect("Failed to read data directory");
        for entry in entries {
            let entry = entry.expect("Failed to read entry");
            if entry.file_name().to_str().unwrap().ends_with("json") {
                let path = entry.path();
                let path = path.to_str().expect("Failed to convert path to string");
                let data = load_satellite_status(path.to_string());
                println!("Loaded {}", entry.file_name().to_str().unwrap());
                statuses.extend(data);
            }
        }

        let mut dataset: Vec<SatelliteStatusTimeSeriesData> =
            Vec::<SatelliteStatusTimeSeriesData>::new();
        for time_series_data in statuses.windows(11) {
            let array: SatelliteStatusTimeSeriesData =
                time_series_data.to_vec().try_into().unwrap();
            dataset.push(array);
        }
        info!("Loaded {} statuses", statuses.len());
        let dataset = InMemDataset::new(dataset);
        Ok(Self { dataset })
    }
}
```
ä¸ºäº†èƒ½å¤Ÿè®©Burnçš„è®­ç»ƒå™¨è‡ªåŠ¨è¯»å–ï¼Œéœ€è¦å®ç°`Dataset` trait
```rust
impl Dataset<SatelliteStatusTimeSeriesData> for SatelliteStatusTimeSeriesDataset {
    fn get(&self, index: usize) -> Option<SatelliteStatusTimeSeriesData> {
        self.dataset.get(index)
    }

    fn len(&self) -> usize {
        self.dataset.len()
    }
}
```

## æ•°æ®Batché¢„å¤„ç†
åœ¨æ­¤éœ€è¦å®ç°çœŸæ­£ç”¨äºè®­ç»ƒçš„Batchï¼ŒåŒ…æ‹¬è¾“å…¥ä¸è¾“å‡ºï¼Œå› æ­¤å…ˆå®šä¹‰ä¸€ä¸ªBatchçš„struct
```rust
#[derive(Clone, Debug)]
pub struct SatelliteStatusBatch<B: Backend> {
    // [batch_size, time_length(10), input_datas]
    pub source: Tensor<B, 3>,
    // [batch_size, target_datas]
    pub target: Tensor<B, 2>,
}
```
è¿˜éœ€è¦ä¸€ä¸ªBatcherçš„structï¼Œæ¥å®ç°å…·ä½“çš„åŠŸèƒ½
```rust
#[derive(Clone)]
pub struct SatelliteStatusBatcher<B: Backend> {
    device: B::Device,
}

impl<B: Backend> SatelliteStatusBatcher<B> {
    pub fn new(device: B::Device) -> Self {
        Self { device }
    }
}
```

åœ¨è¿™ä¹‹åæ˜¯æœ€å…³é”®çš„ï¼Œè¿æ¥æ•°æ®é›†ä¸Batchçš„å‡½æ•°ï¼Œè¿™é‡Œéœ€è¦å®ç°`Batcher` trait
```rust
impl<B: Backend> Batcher<æ•°æ®é›†, Batch<B>>
    for Batcher<B>
```
ç„¶ååœ¨å®ç°çš„`batch`å‡½æ•°é‡Œæ¥å¤„ç†æ•°æ®ï¼Œæ³¨æ„æ­¤æ—¶çš„`SatelliteStatusBatch`ä¸ºåé¢è®­ç»ƒç”¨çš„`TrainConfig`é‡Œçš„`batch_size`ä¸ªBatchï¼Œ  
ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸€ä¸ªæ•°æ®çš„sourceåº”å½“æ˜¯`time_length(10) * input_datas`è¿™ä¸ªäºŒç»´Tensorï¼Œä½†æ˜¯è¦ä¹˜ä¸€ä¸ª`batch_size`å› è€Œå˜ä¸ºäº†ä¸‰ç»´çš„Tensor
```rust
impl<B: Backend> Batcher<SatelliteStatusTimeSeriesData, SatelliteStatusBatch<B>>
    for SatelliteStatusBatcher<B>
{
    fn batch(&self, items: Vec<SatelliteStatusTimeSeriesData>) -> SatelliteStatusBatch<B> {
        let mut sources = Vec::<Tensor<B, 2>>::new();
        let mut targets = Vec::<Tensor<B, 1>>::new();

        for time_series_data in items {
            let source: Vec<Tensor<B, 1>> = time_series_data
                .iter()
                .take(10)
                .map(|item| {
                    Data::<f64, 1>::from([
                        item.range / 2732.,
                        item.snr / 33.,
                        item.latency * 10.,
                        item.channel_capacity / 162525.,
                    ])
                })
                .map(|data| Tensor::<B, 1>::from_data(data.convert(), &self.device))
                .collect();

            let mut target: Vec<Tensor<B, 1>> = time_series_data
                .iter()
                .skip(10)
                .map(|item| {
                    Data::<f64, 1>::from([
                        item.range / 2732.,
                        item.snr / 33.,
                        item.latency * 10.,
                        item.channel_capacity / 162525.,
                    ])
                })
                .map(|data| Tensor::<B, 1>::from_data(data.convert(), &self.device))
                .collect();

            let source: Tensor<B, 2> = Tensor::<B, 1>::stack(source, 0);
            let target = target.remove(0);
            sources.push(source);
            targets.push(target);
        }

        let source: Tensor<B, 3> = Tensor::<B, 2>::stack(sources, 0);
        let target: Tensor<B, 2> = Tensor::<B, 1>::stack(targets, 0);

        SatelliteStatusBatch { source, target }
    }
}
```
å¤„ç†çš„æ—¶å€™åŠ¡å¿…è¦æ³¨æ„æ•°æ®çš„å½’ä¸€åŒ–å¤„ç†ï¼Œä¸ç„¶ä¼šå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸æˆ–è€…æ¢¯åº¦æ¶ˆå¤±ï¼Œæ­¤å¤„ç”±äºæ˜¯ä¸€ä¸ªDemoå› è€Œç›´æ¥é‡‡ç”¨magic numberäº†

## æ¨¡å‹ç¼–å†™
é‚£ä¹ˆé¦–å…ˆå‘¢æˆ‘ä»¬éœ€è¦å…ˆå®šä¹‰æ¨¡å‹çš„ç»“æ„ï¼Œè¿™ç‚¹å’ŒPytorchä¸­çš„å¤„ç†å¾ˆåƒ  
æ­¤å¤„æ˜¯å…ˆç”¨PositionalEncodingæ·»åŠ æ—¶é—´åºåˆ—å‚æ•°ï¼Œä¸ç„¶çš„è¯transformerä¸ä¼šè€ƒè™‘æ•°æ®çš„å…ˆåé¡ºåºé—®é¢˜ï¼›å†ä½¿ç”¨æ ‡å‡†encoderåç”¨ä¸€ä¸ªçº¿æ€§å±‚åšdecoder
```rust
#[derive(Module, Debug)]
pub struct SatelliteStatusPredictor<B: Backend> {
    positional_encoding: PositionalEncoding<B>,
    encoder: TransformerEncoder<B>,
    decoder: Linear<B>,
}
```
åŠ¡å¿…æ³¨æ„è¦åŠ ä¸Š`Module` deriveä¸ç„¶çš„è¯ä¼šå¯¼è‡´AutoGradçš„Backendå‡ºé”™  
ç„¶åè¦å®šä¹‰æ¯ä¸€å±‚å…·ä½“çš„è¾“å…¥è¾“å‡ºå¤§å°ç­‰è¯¦ç»†é…ç½®
```rust
#[derive(Config)]
pub struct SatelliteStatusPredictorConfig {}

impl SatelliteStatusPredictorConfig {
    pub fn init<B: Backend>(&self, device: &B::Device) -> SatelliteStatusPredictor<B> {
        let positional_encoding = PositionalEncodingConfig::new(4).init(device);
        let encoder = TransformerEncoderConfig::new(4, 64, 4, 4).init(device);
        let decoder = LinearConfig::new(4, 3).init(device);
        SatelliteStatusPredictor {
            positional_encoding,
            encoder,
            decoder,
        }
    }
}
```
æ¨¡å‹é…ç½®å®Œæˆåè¦ç¼–å†™æ¨¡å‹forwardéƒ¨åˆ†
```rust
pub fn forward(&self, source: Tensor<B, 3>) -> Tensor<B, 2> {
    let positional_encoded = self.positional_encoding.forward(source);
    let encoded = self
        .encoder
        .forward(TransformerEncoderInput::new(positional_encoded));
    let decoded = self.decoder.forward(encoded);
    let [batch_size, _, d_model] = decoded.dims();
    decoded.slice([0..batch_size, 0..1, 0..d_model]).squeeze(1)
}
```
å†å†™ä¸€ä¸‹è®­ç»ƒçš„æ—¶å€™forwardçš„è¿‡ç¨‹ï¼Œåœ¨è¿™é‡Œåº”å½“è¦è®¡ç®—lossï¼ŒBurnæä¾›äº†RegressionOutputå’ŒClassificationOutputä¸¤ç§ä¸åŒçš„è¾“å‡ºï¼Œæ ¹æ®è‡ªå·±éœ€è¦é€‰æ‹©ä¸€ç§å³å¯
```rust
pub fn forward_training(
    &self,
    source: Tensor<B, 3>,
    targets: Tensor<B, 2>,
) -> RegressionOutput<B> {
    let predicted = self.forward(source);
    let [batch_size, _] = targets.dims();
    let targets = targets.clone().slice([0..batch_size, 0..3]);
    let loss = MseLoss::new().forward(predicted.clone(), targets.clone(), Reduction::Sum);
    RegressionOutput::new(loss, predicted, targets)
}
```
è¿™ä¹‹åå…¶å®è®­ç»ƒè¿‡ç¨‹å°±å·²ç»å¯ä»¥æ‰‹åŠ¨è¿›è¡Œäº†ï¼Œä½†æ˜¯ä¸ºäº†æ–¹ä¾¿å¯ä»¥é‡‡ç”¨Burnæä¾›çš„è‡ªåŠ¨è®­ç»ƒå™¨ï¼Œä¹Ÿå¾ˆç®€å•åªéœ€è¦å®ç°ä¸¤ä¸ªtraitå³å¯
```rust
impl<B: AutodiffBackend> TrainStep<SatelliteStatusBatch<B>, RegressionOutput<B>>
    for SatelliteStatusPredictor<B>
{
    fn step(
        &self,
        batch: SatelliteStatusBatch<B>,
    ) -> burn::train::TrainOutput<RegressionOutput<B>> {
        let item = self.forward_training(batch.source, batch.target);
        TrainOutput::new(self, item.loss.backward(), item)
    }
}

impl<B: Backend> ValidStep<SatelliteStatusBatch<B>, RegressionOutput<B>>
    for SatelliteStatusPredictor<B>
{
    fn step(&self, batch: SatelliteStatusBatch<B>) -> RegressionOutput<B> {
        self.forward_training(batch.source, batch.target)
    }
}
```

## è‡ªåŠ¨è®­ç»ƒ
Burnå¾ˆè´´å¿ƒçš„ç»™é…äº†ä¸ªæ§åˆ¶å°UIï¼Œæ¥å®æ—¶æŸ¥çœ‹è®­ç»ƒè¿›åº¦ï¼Œå¾ˆnice  
é¦–å…ˆå®šä¹‰ä¸€ä¸ªè®­ç»ƒçš„é…ç½®struct
```rust
#[derive(Config)]
struct TrainConfig {
    pub model: SatelliteStatusPredictorConfig,
    pub optimizer: AdamConfig,
    #[config(default = 1.0e-2)]
    pub learning_rate: f64,
    #[config(default = 233)]
    pub seed: u64,
    #[config(default = 256)]
    pub batch_size: usize,
    #[config(default = 10)]
    pub num_epochs: usize,
}
```
åŒæ ·æ˜¯æ³¨æ„deriveä¸è¦è½ä¸‹  
ç„¶åå¯ä»¥å¼€å§‹é…ç½®GPUåŠ é€Ÿéƒ¨åˆ†å¹¶å‡†å¤‡è®­ç»ƒ
```rust
type MyBackend = Wgpu<AutoGraphicsApi, f32, i32>;
type MyAutodiffBackend = Autodiff<MyBackend>;
let device = burn::backend::wgpu::WgpuDevice::default();

let config = TrainConfig::new(SatelliteStatusPredictorConfig::new(), AdamConfig::new());
train::<MyAutodiffBackend>(config, device);
```
è®­ç»ƒæ—¶å€™å…ˆè¦è¿›ä¸€æ­¥å°†æ•´ä¸ªæ•°æ®é›†åˆ‡åˆ†æˆè®­ç»ƒé›†å’ŒéªŒè¯é›†ä¸¤éƒ¨åˆ†
```rust
let dataset: ShuffledDataset<SatelliteStatusTimeSeriesDataset, [data::SatelliteStatus; 11]> =
    ShuffledDataset::with_seed(
        SatelliteStatusTimeSeriesDataset::new().unwrap(),
        config.seed,
    );

let data_length = dataset.len();
let train_size = (data_length as f32 * 0.8) as usize;
let test_size = data_length - train_size;
let dataset_train: PartialDataset<
    ShuffledDataset<SatelliteStatusTimeSeriesDataset, [data::SatelliteStatus; 11]>,
    [data::SatelliteStatus; 11],
> = PartialDataset::new(dataset, 0, train_size);

let dataset: ShuffledDataset<SatelliteStatusTimeSeriesDataset, [data::SatelliteStatus; 11]> =
    ShuffledDataset::with_seed(
        SatelliteStatusTimeSeriesDataset::new().unwrap(),
        config.seed,
    );
let dataset_val: PartialDataset<
    ShuffledDataset<SatelliteStatusTimeSeriesDataset, [data::SatelliteStatus; 11]>,
    [data::SatelliteStatus; 11],
> = PartialDataset::new(dataset, train_size, train_size + test_size);
let batcher_train = SatelliteStatusBatcher::<B>::new(device.clone());
let batcher_valid = SatelliteStatusBatcher::<B::InnerBackend>::new(device.clone());
let dataloader_train = DataLoaderBuilder::new(batcher_train)
    .batch_size(config.batch_size)
    .shuffle(config.seed)
    .build(dataset_train);

let dataloader_valid = DataLoaderBuilder::new(batcher_valid)
    .batch_size(config.batch_size)
    .shuffle(config.seed)
    .build(dataset_val);
```
å®Œæˆåä¾¿å¯ä»¥ç›´æ¥æ‰”ç»™Burnçš„è‡ªåŠ¨è®­ç»ƒå™¨æ¥è¿›è¡Œè®­ç»ƒäº†ï¼Œè®­ç»ƒå®Œæˆåä¿å­˜checkpointåˆ°æŒ‡å®šæ–‡ä»¶å³å¯
```rust
B::seed(config.seed);

let learner = LearnerBuilder::new("run")
    .metric_train_numeric(LossMetric::new())
    .metric_valid_numeric(LossMetric::new())
    .with_file_checkpointer(CompactRecorder::new())
    .devices(vec![device.clone()])
    .num_epochs(config.num_epochs)
    .summary()
    .build(
        config.model.init::<B>(&device),
        config.optimizer.init(),
        config.learning_rate,
    );
let model_trained = learner.fit(dataloader_train, dataloader_valid);
model_trained
    .save_file("run/model", &CompactRecorder::new())
    .expect("Trained model should be saved successfully");
```
è¿™æ ·ä¾¿å¯ä»¥ç”¨Burnæ¥è®­ç»ƒä¸€ä¸ªç®€å•çš„Transformeräº†ï¼Œå½“ç„¶éšç€æ¨¡å‹çš„å¤æ‚åº¦å¢å¤§éœ€è¦é¢å¤–å¤„ç†çš„éƒ¨åˆ†ä¹Ÿæ›´å¤šï¼Œ
è¿‡æ®µæ—¶é—´çš„è¯æˆ‘ä¼šå†å†™ä¸€ä¸ªåˆ©ç”¨Burnå°†ONNXæ¨¡å‹æ¨ç†åµŒå…¥åˆ°åŸºäºFlutterçš„ç§»åŠ¨ç«¯APPä¸­çš„æ–‡ç« ï¼Œæ¯•ç«Ÿåˆ©ç”¨Rustçš„è¯æ•ˆç‡è¦æ¯”Dartæœ¬èº«é«˜ä¸Šä¸å°‘

> åœ¨çœ‹å››æœˆæ–°ç•ªï¼Œé»‘é•¿ç›´yydså•ŠğŸ˜œï¼Œè™½ç„¶æ˜¯æµªæ¼«çˆ±æƒ…æ•…äº‹ï¼Œä½†æ˜¯å¼ºè€…ä¹‹é—´çš„æ•…äº‹æ€»æ˜¯èƒ½ä»¤äººç¥å¾€å‘¢ï¼Œè¿˜æ˜¯å¾—ä¸æ–­å˜å¼ºå•ŠğŸ‘¾